{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cd1cf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path # Directories, gotta have em.\n",
    "import pickle # Better than .csv + a cute name.\n",
    "import pandas as pd # DataFrames. Looping is easy. Obscure functions are fast.\n",
    "import numpy as np # do math on vectors with more obscure functions.\n",
    "import re # one-way encryption for your codebase\n",
    "import pathlib\n",
    "from scipy import stats\n",
    "\n",
    "# Interactive Computing\n",
    "from timeit import default_timer as tm\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Spacy\n",
    "import spacy\n",
    "from spacy.tokens import Doc, DocBin\n",
    "nlp = spacy.load('en_core_web_trf')\n",
    "if Doc.has_extension('name'):\n",
    "    pass\n",
    "else:\n",
    "    Doc.set_extension('name', default=None)\n",
    "    \n",
    "# LDA\n",
    "from gensim.models import Phrases\n",
    "from gensim.models import LdaModel # just for loading saved models\n",
    "from gensim.models import LdaMulticore # for computing topic models\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "# Visualization\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "pyLDAvis.enable_notebook()\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a936a2f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id_comp</th>\n",
       "      <th>full_text</th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>discourse_start</th>\n",
       "      <th>discourse_end</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>discourse_type_num</th>\n",
       "      <th>hierarchical_id</th>\n",
       "      <th>hierarchical_text</th>\n",
       "      <th>hierarchical_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>Phones\\n\\nModern humans today are always on th...</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Phones\\n\\n</td>\n",
       "      <td>Unannotated</td>\n",
       "      <td>Unannotated 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>Phones\\n\\nModern humans today are always on th...</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>8.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>Modern humans today are always on their phone....</td>\n",
       "      <td>Lead</td>\n",
       "      <td>Lead 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>Phones\\n\\nModern humans today are always on th...</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>230.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>They are some really bad consequences when stu...</td>\n",
       "      <td>Position</td>\n",
       "      <td>Position 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>Phones\\n\\nModern humans today are always on th...</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>313.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>Some certain areas in the United States ban ph...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 1</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>They are some really bad consequences when stu...</td>\n",
       "      <td>Position</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>Phones\\n\\nModern humans today are always on th...</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>402.0</td>\n",
       "      <td>757.0</td>\n",
       "      <td>When people have phones, they know about certa...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>They are some really bad consequences when stu...</td>\n",
       "      <td>Position</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285378</th>\n",
       "      <td>DF920E0A7337</td>\n",
       "      <td>Have you ever asked more than one person for h...</td>\n",
       "      <td>1.617757e+12</td>\n",
       "      <td>1624.0</td>\n",
       "      <td>2398.0</td>\n",
       "      <td>One person can change your option, but it may ...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 2</td>\n",
       "      <td>1.617757e+12</td>\n",
       "      <td>it can change your perspective of a topic,</td>\n",
       "      <td>Claim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285379</th>\n",
       "      <td>DF920E0A7337</td>\n",
       "      <td>Have you ever asked more than one person for h...</td>\n",
       "      <td>1.617757e+12</td>\n",
       "      <td>2399.0</td>\n",
       "      <td>2454.0</td>\n",
       "      <td>\\nFinally, it informs you about what other peo...</td>\n",
       "      <td>Unannotated</td>\n",
       "      <td>Unannotated 5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285380</th>\n",
       "      <td>DF920E0A7337</td>\n",
       "      <td>Have you ever asked more than one person for h...</td>\n",
       "      <td>1.617757e+12</td>\n",
       "      <td>2455.0</td>\n",
       "      <td>3266.0</td>\n",
       "      <td>Having more than one person's opinion might le...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 3</td>\n",
       "      <td>1.617757e+12</td>\n",
       "      <td>it informs you about what other people enjoy.</td>\n",
       "      <td>Claim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285381</th>\n",
       "      <td>DF920E0A7337</td>\n",
       "      <td>Have you ever asked more than one person for h...</td>\n",
       "      <td>1.617757e+12</td>\n",
       "      <td>3267.0</td>\n",
       "      <td>3281.0</td>\n",
       "      <td>\\nIn conclusion,</td>\n",
       "      <td>Unannotated</td>\n",
       "      <td>Unannotated 6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285382</th>\n",
       "      <td>DF920E0A7337</td>\n",
       "      <td>Have you ever asked more than one person for h...</td>\n",
       "      <td>1.617757e+12</td>\n",
       "      <td>3282.0</td>\n",
       "      <td>3629.0</td>\n",
       "      <td>finding more than one persons view is better ...</td>\n",
       "      <td>Concluding Statement</td>\n",
       "      <td>Concluding Statement 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>285383 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       essay_id_comp                                          full_text  \\\n",
       "0       423A1CA112E2  Phones\\n\\nModern humans today are always on th...   \n",
       "1       423A1CA112E2  Phones\\n\\nModern humans today are always on th...   \n",
       "2       423A1CA112E2  Phones\\n\\nModern humans today are always on th...   \n",
       "3       423A1CA112E2  Phones\\n\\nModern humans today are always on th...   \n",
       "4       423A1CA112E2  Phones\\n\\nModern humans today are always on th...   \n",
       "...              ...                                                ...   \n",
       "285378  DF920E0A7337  Have you ever asked more than one person for h...   \n",
       "285379  DF920E0A7337  Have you ever asked more than one person for h...   \n",
       "285380  DF920E0A7337  Have you ever asked more than one person for h...   \n",
       "285381  DF920E0A7337  Have you ever asked more than one person for h...   \n",
       "285382  DF920E0A7337  Have you ever asked more than one person for h...   \n",
       "\n",
       "        discourse_id  discourse_start  discourse_end  \\\n",
       "0       1.622628e+12              0.0            7.0   \n",
       "1       1.622628e+12              8.0          229.0   \n",
       "2       1.622628e+12            230.0          312.0   \n",
       "3       1.622628e+12            313.0          400.0   \n",
       "4       1.622628e+12            402.0          757.0   \n",
       "...              ...              ...            ...   \n",
       "285378  1.617757e+12           1624.0         2398.0   \n",
       "285379  1.617757e+12           2399.0         2454.0   \n",
       "285380  1.617757e+12           2455.0         3266.0   \n",
       "285381  1.617757e+12           3267.0         3281.0   \n",
       "285382  1.617757e+12           3282.0         3629.0   \n",
       "\n",
       "                                           discourse_text  \\\n",
       "0                                              Phones\\n\\n   \n",
       "1       Modern humans today are always on their phone....   \n",
       "2       They are some really bad consequences when stu...   \n",
       "3       Some certain areas in the United States ban ph...   \n",
       "4       When people have phones, they know about certa...   \n",
       "...                                                   ...   \n",
       "285378  One person can change your option, but it may ...   \n",
       "285379  \\nFinally, it informs you about what other peo...   \n",
       "285380  Having more than one person's opinion might le...   \n",
       "285381                                   \\nIn conclusion,   \n",
       "285382   finding more than one persons view is better ...   \n",
       "\n",
       "              discourse_type      discourse_type_num  hierarchical_id  \\\n",
       "0                Unannotated           Unannotated 1              NaN   \n",
       "1                       Lead                  Lead 1              NaN   \n",
       "2                   Position              Position 1              NaN   \n",
       "3                   Evidence              Evidence 1     1.622628e+12   \n",
       "4                   Evidence              Evidence 2     1.622628e+12   \n",
       "...                      ...                     ...              ...   \n",
       "285378              Evidence              Evidence 2     1.617757e+12   \n",
       "285379           Unannotated           Unannotated 5              NaN   \n",
       "285380              Evidence              Evidence 3     1.617757e+12   \n",
       "285381           Unannotated           Unannotated 6              NaN   \n",
       "285382  Concluding Statement  Concluding Statement 1              NaN   \n",
       "\n",
       "                                        hierarchical_text hierarchical_label  \n",
       "0                                                     NaN                NaN  \n",
       "1                                                     NaN                NaN  \n",
       "2                                                     NaN                NaN  \n",
       "3       They are some really bad consequences when stu...           Position  \n",
       "4       They are some really bad consequences when stu...           Position  \n",
       "...                                                   ...                ...  \n",
       "285378        it can change your perspective of a topic,               Claim  \n",
       "285379                                                NaN                NaN  \n",
       "285380      it informs you about what other people enjoy.              Claim  \n",
       "285381                                                NaN                NaN  \n",
       "285382                                                NaN                NaN  \n",
       "\n",
       "[285383 rows x 11 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "persuade_corpus = pd.read_pickle('persuade_corpus_full.pkl')\n",
    "display(persuade_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fec7fee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Claim', 'Evidence', 'Unannotated', 'Position', 'Concluding Statement',\n",
       "       'Lead', 'Counterclaim', 'Rebuttal'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(persuade_corpus.discourse_type.value_counts().index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5b4c7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# persuade_corpus['full_text'].str.replace('\\n','')\n",
    "\n",
    "# want to make sure I keep the essay id\n",
    "# need to make a dict of possible labels with BOOL values. {\"claim\": False, \"evidence\":True, etc.}\n",
    "# result should be a tuple of (name, text, label_dict)\n",
    "# output should be a collection of spacy docs with ._.name and .cats\n",
    "\n",
    "\n",
    "# add textcategorizer to pipeline\n",
    "# add labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ced6096a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = persuade_corpus[['essay_id_comp', 'discourse_text', 'discourse_type']].copy()\n",
    "df['discourse_text'] = df['discourse_text'].str.replace('\\n','')\n",
    "text_id_tuples = list(df[['discourse_text','essay_id_comp']].itertuples(index=False, name=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "315cfc83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84.19\n"
     ]
    }
   ],
   "source": [
    "spacy_file = 'persuade.spacy'\n",
    "\n",
    "def proc_texts(text_tuples):\n",
    "    doc_bin = DocBin(attrs=[\"ORTH\", \"TAG\", \"HEAD\", \"DEP\", \"LEMMA\", \"MORPH\", \"POS\"], store_user_data=True)\n",
    "    for doc, name in nlp.pipe(text_tuples, as_tuples=True):\n",
    "        doc._.trf_data = None\n",
    "        doc._.name = name\n",
    "#         doc.cats = {} # I can use this to store categories for spacy text categorization later on.\n",
    "        doc_bin.add(doc)\n",
    "    return doc_bin\n",
    "\n",
    "start = tm()\n",
    "if os.path.isfile(spacy_file):\n",
    "    doc_bin = DocBin().from_disk(spacy_file)\n",
    "else:\n",
    "    doc_bin = proc_texts(text_id_tuples)\n",
    "    doc_bin.to_disk(spacy_file)\n",
    "docs = list(doc_bin.get_docs(nlp.vocab))\n",
    "print(round(tm()-start,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "021d70b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'driver', 'emotion', 'driverless', 'the', 'electoral', 'cell', 'election', 'state', 'an', 'vote', 'earth', 'community', 'a', 'venus', 'activity', 'drive', 'technology', 'mars', 'school', 'elector', 'planet', 'phone', 'car', 'president', 'project', 'design', 'student'}\n",
      "{'driver', 'emotion', 'driverless', 'the', 'electoral', 'cell', 'election', 'state', 'an', 'vote', 'earth', 'community', 'a', 'venus', 'activity', 'drive', 'technology', 'mars', 'school', 'elector', 'planet', 'phone', 'car', 'president', 'project', 'design', 'student'}\n"
     ]
    }
   ],
   "source": [
    "nlp.Defaults.stop_words = {'the','an', 'a'}\n",
    "nlp.Defaults.stop_words |= {'car', 'driverless', 'drive', 'mars', 'driver', 'electoral', 'vote', 'president', 'state', 'venus', 'planet', 'earth', 'elector', 'election', 'phone', 'cell', 'technology', 'emotion', 'student', 'project', 'design', 'school', 'community', 'activity'}\n",
    "print(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7050415b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique tokens: 60801\n",
      "Number of unique tokens: 8394\n",
      "Number of documents: 285383\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'--- 19.39 seconds ---'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def reduce_tokens(docs):\n",
    "    '''\n",
    "    Extract alpha tokens\n",
    "    Lemmatizes and makes lowercase\n",
    "    '''\n",
    "    processed_docs = []\n",
    "    for doc in docs:\n",
    "        processed_doc = []\n",
    "        for token in doc:\n",
    "#             if not token.is_punct and not token.is_stop and not token.is_digit and not token.is_space:\n",
    "            if token.is_alpha and not token.is_stop:\n",
    "                processed_doc.append(token.lemma_.lower())\n",
    "        processed_docs.append(processed_doc)\n",
    "    return processed_docs\n",
    "\n",
    "def compute_bigrams(processed_docs):\n",
    "    '''\n",
    "    For any bigrams that occur at least 20 times across all docs,\n",
    "    if that bigram occurs in a doc, \n",
    "    add the bigram to the list of tokens in the doc.\n",
    "    '''\n",
    "    bigram = Phrases(processed_docs, min_count=20)\n",
    "    for idx in range(len(processed_docs)):\n",
    "        for token in bigram[processed_docs[idx]]:\n",
    "            if '_' in token:\n",
    "                # Token is a bigram, add to document.\n",
    "                processed_docs[idx].append(token)\n",
    "    return processed_docs\n",
    "\n",
    "def dictionary_corpus_processing(procced_docs):\n",
    "    # Create a dictionary representation of the documents.\n",
    "    diction = Dictionary(procced_docs)\n",
    "    print('Number of unique tokens: %d' % len(diction))\n",
    "\n",
    "    # Filter out words that occur in less than 20 documents, or more than 50% of the documents.\n",
    "    diction.filter_extremes(no_below=20, no_above=0.5)\n",
    "    print('Number of unique tokens: %d' % len(diction))\n",
    "\n",
    "    # Make a bag of words.\n",
    "    corp = [diction.doc2bow(doc) for doc in procced_docs]\n",
    "    print('Number of documents: %d' % len(corp))\n",
    "    \n",
    "    return corp, diction\n",
    "\n",
    "start = tm()\n",
    "processed_docs = compute_bigrams(reduce_tokens(docs))\n",
    "corpus, dictionary = dictionary_corpus_processing(processed_docs)\n",
    "display(\"--- %s seconds ---\" % round((tm() - start),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a51c41e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No model with 7 topics found. Extracting 7 topics.\n",
      "--- 202.0795381180942 seconds ---\n",
      "Topics Extracted\n",
      "Vizualization saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/opt/conda/lib/python3.8/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/opt/conda/lib/python3.8/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/opt/conda/lib/python3.8/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n"
     ]
    }
   ],
   "source": [
    "def latent_dirichlet_allocation(input_corpus, input_dictionary):\n",
    "    # Set training parameters.\n",
    "    chunksize = 500000\n",
    "    passes = 10\n",
    "    iterations = 5\n",
    "    eval_every = None  # Don't evaluate model perplexity, takes too much time.\n",
    "    \n",
    "    # Make an index to word dictionary.\n",
    "    temp = input_dictionary[0]  # This is only to \"load\" the dictionary.\n",
    "    id2word = input_dictionary.id2token\n",
    "    \n",
    "    # Train LDA model.\n",
    "    start_time = tm()\n",
    "    \n",
    "    model = LdaMulticore(\n",
    "        corpus=input_corpus,\n",
    "        id2word=id2word,\n",
    "        chunksize=chunksize,\n",
    "#         alpha='auto',\n",
    "#         eta='auto',\n",
    "        iterations=iterations,\n",
    "        num_topics=num_topics,\n",
    "        passes=passes,\n",
    "        eval_every=eval_every\n",
    "    )\n",
    "\n",
    "    print(\"--- %s seconds ---\" % (tm() - start_time))\n",
    "    \n",
    "    return(model)\n",
    "\n",
    "num_topics = 7\n",
    "\n",
    "file_path = os.path.join('gensim_models', '{n}_topics'.format(n=num_topics))\n",
    "pathlib.Path(file_path).mkdir(parents=True, exist_ok=True) \n",
    "model_filename = os.path.join(file_path, 'LDA_persuade_{n}_topics_stops_1.gensim'.format(n = num_topics))\n",
    "\n",
    "if os.path.isfile(model_filename):\n",
    "    print('Retrieving Topics from File')\n",
    "    model = LdaModel.load(model_filename)\n",
    "    print('Done.')\n",
    "else:\n",
    "    print('No model with {n} topics found. Extracting {n} topics.'.format(n=num_topics))\n",
    "    model = latent_dirichlet_allocation(corpus, dictionary)\n",
    "    print('Topics Extracted')\n",
    "    model.save(model_filename)\n",
    "    p = gensimvis.prepare(model, corpus, dictionary)\n",
    "    pyLDAvis.save_html(p, 'pyLDAvis_{n}.html'.format(n = num_topics))\n",
    "    print('Vizualization saved.')\n",
    "\n",
    "# Get the documentxtopics as tuples\n",
    "document_topics = model.get_document_topics(corpus, minimum_probability=0, minimum_phi_value=None, per_word_topics=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d87d702a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 285383/285383 [00:26<00:00, 10676.34it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create a label list for topics\n",
    "topic_cols = [f'topic_{i}' for i in range(1,num_topics+1)]\n",
    "\n",
    "# Get the topics for each document using list comprehension\n",
    "topics_by_sample = pd.DataFrame([[y[1] for y in  x] for x in tqdm(document_topics)], columns=topic_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7b9a3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "zscore_topics = pd.DataFrame(stats.zscore(topics_by_sample), columns=topic_cols)\n",
    "\n",
    "# join document data to topic data\n",
    "full_df = df.join(zscore_topics, how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa194f9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_df720_row0_col0{\n",
       "            background-color:  #034165;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_df720_row0_col1{\n",
       "            background-color:  #3790c0;\n",
       "            color:  #000000;\n",
       "        }#T_df720_row0_col2,#T_df720_row6_col1{\n",
       "            background-color:  #f2ecf5;\n",
       "            color:  #000000;\n",
       "        }#T_df720_row0_col3{\n",
       "            background-color:  #76aad0;\n",
       "            color:  #000000;\n",
       "        }#T_df720_row0_col4{\n",
       "            background-color:  #9fbad9;\n",
       "            color:  #000000;\n",
       "        }#T_df720_row0_col5{\n",
       "            background-color:  #bdc8e1;\n",
       "            color:  #000000;\n",
       "        }#T_df720_row0_col6{\n",
       "            background-color:  #cccfe5;\n",
       "            color:  #000000;\n",
       "        }#T_df720_row1_col0{\n",
       "            background-color:  #03466e;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_df720_row1_col1{\n",
       "            background-color:  #2383ba;\n",
       "            color:  #000000;\n",
       "        }#T_df720_row1_col2{\n",
       "            background-color:  #abbfdc;\n",
       "            color:  #000000;\n",
       "        }#T_df720_row1_col3{\n",
       "            background-color:  #4295c3;\n",
       "            color:  #000000;\n",
       "        }#T_df720_row1_col4{\n",
       "            background-color:  #e4e1ef;\n",
       "            color:  #000000;\n",
       "        }#T_df720_row1_col5{\n",
       "            background-color:  #cacee5;\n",
       "            color:  #000000;\n",
       "        }#T_df720_row1_col6{\n",
       "            background-color:  #d1d2e6;\n",
       "            color:  #000000;\n",
       "        }#T_df720_row2_col0{\n",
       "            background-color:  #197db7;\n",
       "            color:  #000000;\n",
       "        }#T_df720_row2_col1,#T_df720_row2_col3,#T_df720_row2_col4,#T_df720_row4_col2,#T_df720_row4_col5,#T_df720_row7_col0,#T_df720_row7_col6{\n",
       "            background-color:  #fff7fb;\n",
       "            color:  #000000;\n",
       "        }#T_df720_row2_col2{\n",
       "            background-color:  #b8c6e0;\n",
       "            color:  #000000;\n",
       "        }#T_df720_row2_col5,#T_df720_row2_col6,#T_df720_row4_col0,#T_df720_row4_col1,#T_df720_row5_col3,#T_df720_row7_col2,#T_df720_row7_col4{\n",
       "            background-color:  #023858;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_df720_row3_col0{\n",
       "            background-color:  #023d60;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_df720_row3_col1{\n",
       "            background-color:  #187cb6;\n",
       "            color:  #000000;\n",
       "        }#T_df720_row3_col2{\n",
       "            background-color:  #e6e2ef;\n",
       "            color:  #000000;\n",
       "        }#T_df720_row3_col3{\n",
       "            background-color:  #8bb2d4;\n",
       "            color:  #000000;\n",
       "        }#T_df720_row3_col4{\n",
       "            background-color:  #0872b1;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_df720_row3_col5{\n",
       "            background-color:  #e0deed;\n",
       "            color:  #000000;\n",
       "        }#T_df720_row3_col6{\n",
       "            background-color:  #f3edf5;\n",
       "            color:  #000000;\n",
       "        }#T_df720_row4_col3{\n",
       "            background-color:  #e7e3f0;\n",
       "            color:  #000000;\n",
       "        }#T_df720_row4_col4{\n",
       "            background-color:  #80aed2;\n",
       "            color:  #000000;\n",
       "        }#T_df720_row4_col6{\n",
       "            background-color:  #94b6d7;\n",
       "            color:  #000000;\n",
       "        }#T_df720_row5_col0{\n",
       "            background-color:  #a2bcda;\n",
       "            color:  #000000;\n",
       "        }#T_df720_row5_col1{\n",
       "            background-color:  #5ea0ca;\n",
       "            color:  #000000;\n",
       "        }#T_df720_row5_col2{\n",
       "            background-color:  #5c9fc9;\n",
       "            color:  #000000;\n",
       "        }#T_df720_row5_col4{\n",
       "            background-color:  #e2dfee;\n",
       "            color:  #000000;\n",
       "        }#T_df720_row5_col5{\n",
       "            background-color:  #c8cde4;\n",
       "            color:  #000000;\n",
       "        }#T_df720_row5_col6{\n",
       "            background-color:  #b0c2de;\n",
       "            color:  #000000;\n",
       "        }#T_df720_row6_col0,#T_df720_row7_col3{\n",
       "            background-color:  #84b0d3;\n",
       "            color:  #000000;\n",
       "        }#T_df720_row6_col2{\n",
       "            background-color:  #5a9ec9;\n",
       "            color:  #000000;\n",
       "        }#T_df720_row6_col3{\n",
       "            background-color:  #eae6f1;\n",
       "            color:  #000000;\n",
       "        }#T_df720_row6_col4{\n",
       "            background-color:  #f8f1f8;\n",
       "            color:  #000000;\n",
       "        }#T_df720_row6_col5{\n",
       "            background-color:  #045788;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_df720_row6_col6{\n",
       "            background-color:  #023e62;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_df720_row7_col1{\n",
       "            background-color:  #6fa7ce;\n",
       "            color:  #000000;\n",
       "        }#T_df720_row7_col5{\n",
       "            background-color:  #04649d;\n",
       "            color:  #f1f1f1;\n",
       "        }</style><table id=\"T_df720_\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >topic_1</th>        <th class=\"col_heading level0 col1\" >topic_2</th>        <th class=\"col_heading level0 col2\" >topic_3</th>        <th class=\"col_heading level0 col3\" >topic_4</th>        <th class=\"col_heading level0 col4\" >topic_5</th>        <th class=\"col_heading level0 col5\" >topic_6</th>        <th class=\"col_heading level0 col6\" >topic_7</th>    </tr>    <tr>        <th class=\"blank level1\" ></th>        <th class=\"col_heading level1 col0\" >mean</th>        <th class=\"col_heading level1 col1\" >mean</th>        <th class=\"col_heading level1 col2\" >mean</th>        <th class=\"col_heading level1 col3\" >mean</th>        <th class=\"col_heading level1 col4\" >mean</th>        <th class=\"col_heading level1 col5\" >mean</th>        <th class=\"col_heading level1 col6\" >mean</th>    </tr>    <tr>        <th class=\"index_name level0\" >discourse_type</th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_df720_level0_row0\" class=\"row_heading level0 row0\" >Claim</th>\n",
       "                        <td id=\"T_df720_row0_col0\" class=\"data row0 col0\" >0.047106</td>\n",
       "                        <td id=\"T_df720_row0_col1\" class=\"data row0 col1\" >0.004050</td>\n",
       "                        <td id=\"T_df720_row0_col2\" class=\"data row0 col2\" >-0.025404</td>\n",
       "                        <td id=\"T_df720_row0_col3\" class=\"data row0 col3\" >0.002809</td>\n",
       "                        <td id=\"T_df720_row0_col4\" class=\"data row0 col4\" >-0.039279</td>\n",
       "                        <td id=\"T_df720_row0_col5\" class=\"data row0 col5\" >-0.018076</td>\n",
       "                        <td id=\"T_df720_row0_col6\" class=\"data row0 col6\" >0.011515</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_df720_level0_row1\" class=\"row_heading level0 row1\" >Concluding Statement</th>\n",
       "                        <td id=\"T_df720_row1_col0\" class=\"data row1 col0\" >0.043098</td>\n",
       "                        <td id=\"T_df720_row1_col1\" class=\"data row1 col1\" >0.018832</td>\n",
       "                        <td id=\"T_df720_row1_col2\" class=\"data row1 col2\" >0.002723</td>\n",
       "                        <td id=\"T_df720_row1_col3\" class=\"data row1 col3\" >0.033921</td>\n",
       "                        <td id=\"T_df720_row1_col4\" class=\"data row1 col4\" >-0.105064</td>\n",
       "                        <td id=\"T_df720_row1_col5\" class=\"data row1 col5\" >-0.028295</td>\n",
       "                        <td id=\"T_df720_row1_col6\" class=\"data row1 col6\" >0.005879</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_df720_level0_row2\" class=\"row_heading level0 row2\" >Counterclaim</th>\n",
       "                        <td id=\"T_df720_row2_col0\" class=\"data row2 col0\" >-0.007909</td>\n",
       "                        <td id=\"T_df720_row2_col1\" class=\"data row2 col1\" >-0.168776</td>\n",
       "                        <td id=\"T_df720_row2_col2\" class=\"data row2 col2\" >-0.001271</td>\n",
       "                        <td id=\"T_df720_row2_col3\" class=\"data row2 col3\" >-0.142952</td>\n",
       "                        <td id=\"T_df720_row2_col4\" class=\"data row2 col4\" >-0.150606</td>\n",
       "                        <td id=\"T_df720_row2_col5\" class=\"data row2 col5\" >0.169615</td>\n",
       "                        <td id=\"T_df720_row2_col6\" class=\"data row2 col6\" >0.240718</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_df720_level0_row3\" class=\"row_heading level0 row3\" >Evidence</th>\n",
       "                        <td id=\"T_df720_row3_col0\" class=\"data row3 col0\" >0.049717</td>\n",
       "                        <td id=\"T_df720_row3_col1\" class=\"data row3 col1\" >0.026138</td>\n",
       "                        <td id=\"T_df720_row3_col2\" class=\"data row3 col2\" >-0.018208</td>\n",
       "                        <td id=\"T_df720_row3_col3\" class=\"data row3 col3\" >-0.011862</td>\n",
       "                        <td id=\"T_df720_row3_col4\" class=\"data row3 col4\" >0.060057</td>\n",
       "                        <td id=\"T_df720_row3_col5\" class=\"data row3 col5\" >-0.053128</td>\n",
       "                        <td id=\"T_df720_row3_col6\" class=\"data row3 col6\" >-0.046570</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_df720_level0_row4\" class=\"row_heading level0 row4\" >Lead</th>\n",
       "                        <td id=\"T_df720_row4_col0\" class=\"data row4 col0\" >0.054028</td>\n",
       "                        <td id=\"T_df720_row4_col1\" class=\"data row4 col1\" >0.109016</td>\n",
       "                        <td id=\"T_df720_row4_col2\" class=\"data row4 col2\" >-0.034086</td>\n",
       "                        <td id=\"T_df720_row4_col3\" class=\"data row4 col3\" >-0.098589</td>\n",
       "                        <td id=\"T_df720_row4_col4\" class=\"data row4 col4\" >-0.016323</td>\n",
       "                        <td id=\"T_df720_row4_col5\" class=\"data row4 col5\" >-0.101141</td>\n",
       "                        <td id=\"T_df720_row4_col6\" class=\"data row4 col6\" >0.060325</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_df720_level0_row5\" class=\"row_heading level0 row5\" >Position</th>\n",
       "                        <td id=\"T_df720_row5_col0\" class=\"data row5 col0\" >-0.071244</td>\n",
       "                        <td id=\"T_df720_row5_col1\" class=\"data row5 col1\" >-0.017708</td>\n",
       "                        <td id=\"T_df720_row5_col2\" class=\"data row5 col2\" >0.021916</td>\n",
       "                        <td id=\"T_df720_row5_col3\" class=\"data row5 col3\" >0.151671</td>\n",
       "                        <td id=\"T_df720_row5_col4\" class=\"data row5 col4\" >-0.101964</td>\n",
       "                        <td id=\"T_df720_row5_col5\" class=\"data row5 col5\" >-0.026531</td>\n",
       "                        <td id=\"T_df720_row5_col6\" class=\"data row5 col6\" >0.036329</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_df720_level0_row6\" class=\"row_heading level0 row6\" >Rebuttal</th>\n",
       "                        <td id=\"T_df720_row6_col0\" class=\"data row6 col0\" >-0.056680</td>\n",
       "                        <td id=\"T_df720_row6_col1\" class=\"data row6 col1\" >-0.144896</td>\n",
       "                        <td id=\"T_df720_row6_col2\" class=\"data row6 col2\" >0.022194</td>\n",
       "                        <td id=\"T_df720_row6_col3\" class=\"data row6 col3\" >-0.102912</td>\n",
       "                        <td id=\"T_df720_row6_col4\" class=\"data row6 col4\" >-0.137442</td>\n",
       "                        <td id=\"T_df720_row6_col5\" class=\"data row6 col5\" >0.138211</td>\n",
       "                        <td id=\"T_df720_row6_col6\" class=\"data row6 col6\" >0.232330</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_df720_level0_row7\" class=\"row_heading level0 row7\" >Unannotated</th>\n",
       "                        <td id=\"T_df720_row7_col0\" class=\"data row7 col0\" >-0.149991</td>\n",
       "                        <td id=\"T_df720_row7_col1\" class=\"data row7 col1\" >-0.026710</td>\n",
       "                        <td id=\"T_df720_row7_col2\" class=\"data row7 col2\" >0.067868</td>\n",
       "                        <td id=\"T_df720_row7_col3\" class=\"data row7 col3\" >-0.008232</td>\n",
       "                        <td id=\"T_df720_row7_col4\" class=\"data row7 col4\" >0.133662</td>\n",
       "                        <td id=\"T_df720_row7_col5\" class=\"data row7 col5\" >0.120916</td>\n",
       "                        <td id=\"T_df720_row7_col6\" class=\"data row7 col6\" >-0.071228</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f8bf530fe80>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.groupby(['discourse_type']).agg(['mean']).style.background_gradient()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c124c1",
   "metadata": {},
   "source": [
    "So if we wanted to only include words in the topic model that have good prompt distribution... well, we would first need to have prompt labels for the data.\n",
    "Barring that, I could manually remove prompt words:\n",
    "['car', 'driverless', 'drive', 'mars', 'driver', 'electoral', 'vote', 'president',\n",
    "'state', 'venus', 'planet', 'earth', 'elector', 'election', 'phone', 'cell', 'technology',\n",
    "'emotion', 'student', 'project', 'design', 'school', 'community', 'activity']\n",
    "\n",
    "That's a good next step:\n",
    " - Should I also remove stop words? I think they are kind of interesting, but maybe removing 'of', 'and', 'the', 'a' would be good.\n",
    " - I will also try to find a number of topics that results in a good coherence score. I chose 8 for my first pass because that is the number of discourse_labels (including \"unannotated\")\n",
    " \n",
    " - get word2vec + doc2vec\n",
    " - classify discourse units based on vector representations\n",
    " - compare unseen vector to existing vectors\n",
    "     - compare unseen vector to every single vector in corpus\n",
    "     - create average vector for each discourse element\n",
    "         - compare unseen vector to average"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
